{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages. See https://github.com/BasisResearch/collab-creatures for repo setup\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "import torch\n",
    "from pyro.infer import SVI, Predictive, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal, init_to_mean\n",
    "\n",
    "from collab.utils import find_repo_root\n",
    "\n",
    "root = find_repo_root()\n",
    "from collab.foraging import random_hungry_followers as rhf\n",
    "from collab.foraging import toolkit as ft\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n",
    "\n",
    "# users can ignore smoke_test -- it's for automatic testing on GitHub, to make sure the notebook runs on future updates to the repository\n",
    "smoke_test = \"CI\" in os.environ\n",
    "num_frames = 5 if smoke_test else 50\n",
    "num_svi_iters = 10 if smoke_test else 1000\n",
    "num_samples = 10 if smoke_test else 1000\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "notebook_starts = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some issues to fix:\n",
    "- frames input in ft.utils.object_from_data doesn't actually change anything. Either remove input, or make it actually change the frame range.\n",
    "- ft.animate_foragers plot overflows, check if it returns figure, and if fig can be resized\n",
    "- ft.animate_foragers assumes no timebins are skipped\n",
    "- sometimes get comfusing bugs when running on too little data (e.g. just 100 frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "foldername = '/Users/emily/Downloads/'\n",
    "filename = '2020_08_01_18_10_16_589437_compressed_Day_spine.npy'\n",
    "fullfilename = os.path.join(foldername, filename)\n",
    "data = np.load(fullfilename)\n",
    "# inspect the data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "# the dimensions of the data are (time, animal_num, XY)\n",
    "\n",
    "#  data shape is (time, animal_num, XY)\n",
    "\n",
    "time_steps, animal_num, _ = data.shape\n",
    "\n",
    "# Create a plot for each animal's trajectory\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "tmin = 1000\n",
    "tmax = 1500\n",
    "\n",
    "for i in range(animal_num):\n",
    "    # Extract the X and Y coordinates for the current animal\n",
    "    x_coords = data[tmin:tmax, i, 0]\n",
    "    y_coords = data[tmin:tmax, i, 1]\n",
    "    \n",
    "    # Plot the trajectory\n",
    "    plt.plot(x_coords, y_coords, label=f'Animal {i+1}')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.title('Animal Trajectories')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data in dataframes as expected for further analysis\n",
    "\n",
    "# make a dataframe with columns for x, y, time, forager (animal_num), and type (always gerbil)\n",
    "# Initialize lists to hold the data for the dataframe\n",
    "time_list = []\n",
    "forager_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "type_list = []\n",
    "\n",
    "# Populate the lists with the data\n",
    "for timei in range(time_steps):\n",
    "    for forager in range(animal_num):\n",
    "        x_list.append(data[timei, forager, 0])\n",
    "        y_list.append(data[timei, forager, 1])\n",
    "        time_list.append(timei)\n",
    "        forager_list.append(forager)\n",
    "        type_list.append('gerbil')\n",
    "\n",
    "# Create the dataframe\n",
    "gerbil_df = pd.DataFrame({\n",
    "    'time': time_list,\n",
    "    'forager': forager_list,\n",
    "    'x': x_list,\n",
    "    'y': y_list,\n",
    "    'type': type_list\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Define the range and location for rewards\n",
    "x_range = range(250, 651)  # x locations from 250 to 650\n",
    "y_location = 700           # y location fixed at 700\n",
    "\n",
    "# Use numpy to efficiently create arrays for the rewards DataFrame\n",
    "x_array = np.tile(np.arange(250, 651), time_steps)\n",
    "y_array = np.full(x_array.shape, y_location)\n",
    "time_array = np.repeat(np.arange(time_steps), len(x_range))\n",
    "\n",
    "# Create the rewards DataFrame\n",
    "rewardsDF = pd.DataFrame({'x': x_array, 'y': y_array, 'time': time_array})\n",
    "\n",
    "# Remove times where any value in gerbil_df is NaN\n",
    "nan_times = gerbil_df[gerbil_df.isna().any(axis=1)]['time']\n",
    "\n",
    "# Filter gerbil_df to exclude rows with these times\n",
    "gerbil_df_clean = gerbil_df[~gerbil_df['time'].isin(nan_times)]\n",
    "\n",
    "# Filter rewardsDF to exclude rows with these times\n",
    "rewardsDF_clean = rewardsDF[~rewardsDF['time'].isin(nan_times)]\n",
    "\n",
    "# Display the cleaned DataFrames\n",
    "print(gerbil_df_clean.head())\n",
    "print(rewardsDF_clean.head())\n",
    "\n",
    "# restrict to time range\n",
    "gerbil_df_clean = gerbil_df_clean[(gerbil_df_clean['time'] >= tmin) & (gerbil_df_clean['time'] <= tmax)]\n",
    "rewardsDF_clean = rewardsDF_clean[(rewardsDF_clean['time'] >= tmin) & (rewardsDF_clean['time'] <= tmax)]\n",
    "\n",
    "forager_object = ft.utils.object_from_data(\n",
    "    gerbil_df_clean,\n",
    "    grid_size=1000,\n",
    "    rewardsDF=rewardsDF_clean,\n",
    "    frames=None, \n",
    "    calculate_step_size_max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.animate_foragers(\n",
    "    forager_object, plot_rewards=True, width=1000, height=710, point_size=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for inference (compute derived predictors)\n",
    "\n",
    "\n",
    "preferred_proximity = 50  # the distance at which foragers prefer to be from each other\n",
    "foragers_derived = ft.derive_predictors(\n",
    "    forager_object, optimal=preferred_proximity, proximity_decay=20, visibility_range=100, dropna=True\n",
    ")\n",
    "\n",
    "\n",
    "def prep_data_for_inference(sim_derived):\n",
    "    df = sim_derived.derivedDF[\n",
    "        [\n",
    "            \"proximity_standardized\",\n",
    "            \"trace_standardized\",\n",
    "            \"visibility\",\n",
    "            \"how_far_squared_scaled\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    for column in df.columns:\n",
    "        df[column] = ft.normalize(df[column])\n",
    "\n",
    "    data = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "    proximity, trace, visibility, how_far_score = (\n",
    "        data[:, 0],\n",
    "        data[:, 1],\n",
    "        data[:, 2],\n",
    "        data[:, 3],\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        str(len(proximity))\n",
    "        + \" data points prepared for inference, dropped \"\n",
    "        + str(len(sim_derived.derivedDF) - len(proximity))\n",
    "        + \" rows with missing values.\"\n",
    "    )\n",
    "    return proximity, trace, visibility, how_far_score\n",
    "\n",
    "\n",
    "\n",
    "proximity, trace, visibility, how_far_score = prep_data_for_inference(\n",
    "    foragers_derived\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.animate_foragers(\n",
    "    foragers_derived,\n",
    "    plot_rewards=True,\n",
    "    width=1000, height=710,\n",
    "    point_size=10,\n",
    "    plot_proximity=2,\n",
    "    proximity_multiplier=25,\n",
    ")\n",
    "\n",
    "# ft.animate_foragers(\n",
    "#     foragers_derived,\n",
    "#     plot_rewards=True,\n",
    "#     width=1000, height=710,\n",
    "#     point_size=10,\n",
    "#     plot_visibility=2,\n",
    "#     plot_traces=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the probabilistic model using pyro (https://pyro.ai/)\n",
    "# p, t, v, b are the coefficients\n",
    "# for proximity, trace, visibility, and the intercept\n",
    "\n",
    "# ps, ts, vs, bs are analogous coefficients,\n",
    "# but they contribute to the variance,\n",
    "# which is not assumed to remain fixed\n",
    "\n",
    "\n",
    "def model_sigmavar(proximity, trace, visibility, how_far_score):\n",
    "    p = pyro.sample(\"p\", dist.Normal(0, 0.2))\n",
    "    t = pyro.sample(\"t\", dist.Normal(0, 0.2))\n",
    "    v = pyro.sample(\"v\", dist.Normal(0, 0.2))\n",
    "    b = pyro.sample(\"b\", dist.Normal(0.5, 0.3))\n",
    "\n",
    "    ps = pyro.sample(\"ps\", dist.Exponential(7))\n",
    "    ts = pyro.sample(\"ts\", dist.Exponential(7))\n",
    "    vs = pyro.sample(\"vs\", dist.Exponential(7))\n",
    "    bs = pyro.sample(\"bs\", dist.Exponential(7))\n",
    "\n",
    "    sigma = pyro.deterministic(\n",
    "        \"sigma\", bs + ps * proximity + ts * trace + vs * visibility\n",
    "    )\n",
    "    mean = pyro.deterministic(\"mean\", b + p * proximity + t * trace + v * visibility)\n",
    "\n",
    "    with pyro.plate(\"data\", len(how_far_score)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=how_far_score)\n",
    "\n",
    "\n",
    "pyro.render_model(\n",
    "    model_sigmavar,\n",
    "    model_args=(proximity, trace, visibility, how_far_score),\n",
    "    render_distributions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for inference, showing results\n",
    "\n",
    "\n",
    "def summary(samples, sites):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        if site_name in sites:\n",
    "            marginal_site = pd.DataFrame(values)\n",
    "            describe = marginal_site.describe(\n",
    "                percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "            ).transpose()\n",
    "            site_stats[site_name] = describe[\n",
    "                [\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]\n",
    "            ]\n",
    "    return site_stats\n",
    "\n",
    "\n",
    "def get_samples(\n",
    "    proximity,\n",
    "    trace,\n",
    "    visibility,\n",
    "    how_far_score,\n",
    "    model=model_sigmavar,\n",
    "    num_svi_iters=num_svi_iters,\n",
    "    num_samples=num_samples,\n",
    "):\n",
    "    guide = AutoMultivariateNormal(model, init_loc_fn=init_to_mean)\n",
    "    svi = SVI(model_sigmavar, guide, optim.Adam({\"lr\": 0.01}), loss=Trace_ELBO())\n",
    "\n",
    "    iterations = []\n",
    "    losses = []\n",
    "\n",
    "    logging.info(f\"Starting SVI inference with {num_svi_iters} iterations.\")\n",
    "    start_time = time.time()\n",
    "    pyro.clear_param_store()\n",
    "    for i in range(num_svi_iters):\n",
    "        elbo = svi.step(proximity, trace, visibility, how_far_score)\n",
    "        iterations.append(i)\n",
    "        losses.append(elbo)\n",
    "        if i % 200 == 0:\n",
    "            logging.info(\"Elbo loss: {}\".format(elbo))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    logging.info(\"SVI inference completed in %.2f seconds.\", elapsed_time)\n",
    "\n",
    "    if not smoke_test:\n",
    "        fig = px.line(\n",
    "            x=iterations, y=losses, title=\"ELBO loss\", template=\"presentation\"\n",
    "        )\n",
    "        labels = {\"iterations\": \"iteration\", \"losses\": \"loss\"}\n",
    "        fig.update_xaxes(showgrid=False, title_text=labels[\"iterations\"])\n",
    "        fig.update_yaxes(showgrid=False, title_text=labels[\"losses\"])\n",
    "        fig.update_layout(width=700)\n",
    "        fig.show()\n",
    "\n",
    "    predictive = Predictive(\n",
    "        model, guide=guide, num_samples=num_samples, return_sites=[\"t\", \"p\", \"v\"]\n",
    "    )\n",
    "    rhf_svi = {\n",
    "        k: v.flatten().reshape(num_samples, -1).detach().cpu().numpy()\n",
    "        for k, v in predictive(proximity, trace, visibility, how_far_score).items()\n",
    "        if k != \"obs\"\n",
    "    }\n",
    "\n",
    "    print(\"SVI-based coefficient marginals:\")\n",
    "    for site, values in summary(rhf_svi, [\"t\", \"p\", \"v\"]).items():\n",
    "        print(\"Site: {}\".format(site))\n",
    "        print(values, \"\\n\")\n",
    "\n",
    "    return {\"svi_samples\": rhf_svi, \"svi_guide\": guide, \"svi_predictive\": predictive}\n",
    "\n",
    "\n",
    "def calculate_R_squared(guide):\n",
    "    predictive = pyro.infer.Predictive(model_sigmavar, guide=guide, num_samples=1000)\n",
    "    predictions = predictive(proximity, trace, visibility, how_far_score)\n",
    "\n",
    "    simulated_outcome = (\n",
    "        predictions[\"b\"]\n",
    "        + predictions[\"p\"] * proximity\n",
    "        + predictions[\"t\"] * trace\n",
    "        + predictions[\"v\"] * visibility\n",
    "    )\n",
    "\n",
    "    mean_sim_outcome = simulated_outcome.mean(0).detach().cpu().numpy()\n",
    "\n",
    "    observed_mean = torch.mean(how_far_score)\n",
    "\n",
    "    tss = torch.sum((how_far_score - observed_mean) ** 2)\n",
    "    rss = torch.sum((how_far_score - mean_sim_outcome) ** 2)\n",
    "\n",
    "    r_squared = 1 - (rss / tss)\n",
    "\n",
    "    return r_squared.float().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose issue... proximity is all NaNs. \n",
    "proximity.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_random = get_samples(proximity, trace, visibility, how_far_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.plot_coefs(\n",
    "    samples_random, \"Gerbils\", nbins=120, ann_start_y=160, ann_break_y=50\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collab_from_setup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
